---
title: "P8105_hw3_xz2809"
author: "Coco"
date: "10/4/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(p8105.datasets)

theme_set(theme_bw()+theme(legend.position = "bottom"))
```

##Problem 1
This problem uses the BRFSS data. here is the **code chunks** for data cleaning and formatting. 
```{r}
data("brfss_smart2010")
brfss_smart2010=
  janitor::clean_names(brfss_smart2010) %>% 
  filter(topic=="Overall Health") %>% 
  select(-topic) %>% 
  select(-class) %>% 
  select(-question) %>% 
  select(-sample_size) %>%
  select(-(confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(states = locationabbr)
brfss_smart2010 <- brfss_smart2010[, c("year", "states","locationdesc","excellent","very_good","good","fair","poor")]
```

Here is the **code chunk** to do the analysis of BRFSS data. 
```{r}
num_state= brfss_smart2010 %>%
  filter(year == 2002) %>% 
  count(states) 

brfss_smart2010 %>% 
  group_by(year,states) %>% 
  count(states) %>% 
  ggplot(aes(x = year, y = n, color = states))+geom_line()

brfss_smart2010 %>% 
  filter(year==2002 | year==2006 | year==2010) %>% 
  filter(states =="NY") %>% 
  group_by(year,states) %>% 
  mutate (mean = mean(excellent),
          sd = sd(excellent)) %>% 
  filter(locationdesc == "NY - New York County") %>% 
  select(year,mean,sd) %>%
  knitr::kable(digits = 3)


brfss_smart2010 %>% 
  group_by(year,states) %>% 
  mutate(
    ex_mean = mean(excellent),
    verygood_mean = mean(very_good),
    good_mean = mean(good),
    fair_mean = mean(fair),
    poor_mean = mean(poor)) %>% 
  select(year,states,ex_mean:poor_mean)

```


##Problem 2
This problem uses the Instacart data.
```{r}
data("instacart")
```
How many aisles are there, and which aisles are the most items ordered from?

Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.

Make a table showing the most popular item aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”

Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
num_aisle = instacart %>% 
  count(aisle_id)  
max(num_aisle$n)

x = instacart %>% 
  group_by(aisle_id) %>% 
  count(product_id) %>% 
  group_by(aisle_id) %>% 
  mutate(num_items = sum(n)) %>% 
  distinct(aisle_id,num_items)

ggplot(x, aes(x = aisle_id, y = num_items)) + geom_point()
  
```

Make a table showing the most popular item aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”

```{r}
y = instacart %>% 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle=="packaged vegetables fruits") %>% 
  mutate(aisle = as.factor(aisle)) %>% 
  group_by(aisle,product_id,product_name) %>% 
  count()

df.max <- aggregate(n ~ aisle, y, max)

```

Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
z = instacart %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  select(order_hour_of_day,product_name,order_dow) %>% 
  group_by(product_name,order_dow) %>% 
  mutate(mean_hour_day = mean (order_hour_of_day)) %>% 
  distinct(product_name,mean_hour_day,order_dow)
```


##Problem3 
```{r}
data("ny_noaa")
```

```{r}
ny_noaa_df= ny_noaa %>% 
  separate(date, into = c("year","month","date"),sep = "-") %>% 
  janitor::clean_names() %>% 
  mutate(tmin = as.numeric(tmin),
         tmax = as.numeric(tmax),
         id = as.factor(id),
         ave = tmax - tmin)
```

```{r}
MaxTable <- function(x){
     m <- unique(x)
     m[which.max(tabulate(match(x,m)))]
}
MaxTable(ny_noaa_df$snow)


```
Make a two-panel plot showing the average temperature in January and in July in each station across years. Is there any observable / interpretable structure? Any outliers?

```{r}

mean_ave_df = ny_noaa_df %>% 
  filter(month=="07" | month=="01") %>% 
  group_by(year,month) %>% 
  filter(!is.na(tmax) & !is.na(tmin)) %>% 
  mutate(ave_month = mean(ave)) %>% 
  distinct(year, id, ave_month)


```








